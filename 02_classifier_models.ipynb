{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "WhiteKernel, DotProduct, RBF, ConstantKernel, \n",
    "Matern, RationalQuadratic, ExpSineSquared\n",
    ")\n",
    "\n",
    "# from sklearn.metrics import PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the dataset and separate the label from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_excel('./data/PCOS_data_without_infertility.xlsx', sheet_name=\"Full_new\")\n",
    "dataset2.drop(columns = 'Unnamed: 44', inplace = True)\n",
    "dataset2.loc[dataset2['II    beta-HCG(mIU/mL)'] == '1.99.', 'II    beta-HCG(mIU/mL)'] = 1.99\n",
    "dataset2['II    beta-HCG(mIU/mL)'] = dataset2['II    beta-HCG(mIU/mL)'].astype(float)\n",
    "dataset2.loc[dataset2['AMH(ng/mL)'] == 'a', 'AMH(ng/mL)'] = np.nan\n",
    "dataset2['AMH(ng/mL)'] = dataset2['AMH(ng/mL)'].astype(float)\n",
    "dataset2 = dataset2.dropna()\n",
    "\n",
    "y = dataset2['PCOS (Y/N)']\n",
    "features = list(dataset2.columns)\n",
    "features.remove('Sl. No')\n",
    "features.remove('Patient File No.')\n",
    "features.remove('PCOS (Y/N)')\n",
    "X = dataset2[features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define models to test: classifiers as we have a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3, n_jobs=4),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate accuracy, precision, recall, F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Scikit-learn's f1-score calculates a different value than what I calculate from the confusion matrix \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors 0.7480916030534351 0.8903654485049834 0.8903654485049833\n",
      "Linear SVM 0.8175182481751825 0.9152542372881356 0.9152542372881356\n",
      "RBF SVM 0.0 0.8066298342541436 0.8066298342541437\n",
      "Gaussian Process 0.8029197080291971 0.9084745762711866 0.9084745762711864\n",
      "Decision Tree 0.7083333333333334 0.8541666666666666 0.8541666666666666\n",
      "Random Forest 0.5544554455445545 0.86404833836858 0.8640483383685801\n",
      "Neural Net 0.8027210884353742 0.8982456140350877 0.8982456140350877\n",
      "AdaBoost 0.7794117647058824 0.8986486486486487 0.8986486486486487\n",
      "Naive Bayes 0.6598984771573604 0.7148936170212765 0.7148936170212766\n",
      "QDA 0.7307692307692307 0.8478260869565217 0.8478260869565217\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf = make_pipeline(StandardScaler(), clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # accuracy\n",
    "    score = clf.score(X_test, y_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # f1 score\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # true positive\n",
    "    tp = cm[0,0]\n",
    "    tn = cm[1,1]\n",
    "    # false positive\n",
    "    fp = cm[0,1]\n",
    "    # false negative\n",
    "    fn = cm[1,0]\n",
    "    # Precision is the fraction of the correctly classified instances from the total classified instances\n",
    "    precision = tp / (tp + fp)\n",
    "    # Recall is the fraction of the correctly classified instances from the total classified instances\n",
    "    recall = tp / (tp + fn)\n",
    "    # F1-score\n",
    "    f1s = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    print(name, f1, f1s, 2*tp / (2*tp+fp+fn))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation: Without hyperparameter optimization, linear SVM, Gaussian process and Neural Net have the highest accuracy and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# Define a function that compares the CV performance of a set of predetermined models \n",
    "def cv_comparison(models, X, y, cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    cv_metrics = pd.DataFrame(columns = ['Model','Accuracy', 'Precision', 'Recall', 'F1_score', 'ROC_AUC', 'F1', 'DOF', 'Coefficients'])\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    rocaucs = []\n",
    "    \n",
    "    # Loop through the models, run a CV, add the average scores to the DataFrame and the scores of \n",
    "    # all CVs to the list\n",
    "    for model in models:\n",
    "        # calculate model complexity\n",
    "        number_of_model_coeffs = 0\n",
    "        try:\n",
    "            for i in model.coef_:\n",
    "                if i != 0:\n",
    "                    number_of_model_coeffs +=1\n",
    "            coefficients = model.coef_\n",
    "        except:\n",
    "            number_of_model_coeffs = np.nan\n",
    "            coefficients = np.nan\n",
    "        \n",
    "        # get cross-validation metrics\n",
    "        cv_results = cross_validate(model, X, y, \n",
    "                                    scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], \n",
    "                                    cv=cv,n_jobs=4)\n",
    "        \n",
    "        # save metrics\n",
    "        accuracy = np.round(cv_results['test_accuracy'].mean(),4)\n",
    "        accuracies.append(cv_results['test_accuracy'])\n",
    "        precision = np.round(cv_results['test_precision'].mean(),4)\n",
    "        precisions.append(cv_results['test_precision'])\n",
    "        recall = np.round(cv_results['test_recall'].mean(),4)\n",
    "        recalls.append(cv_results['test_recall'])\n",
    "        f1 = np.round(cv_results['test_f1'].mean(),4)\n",
    "        f1_scores.append(cv_results['test_f1'])\n",
    "        rocauc = np.round(cv_results['test_roc_auc'].mean(),4)\n",
    "        rocaucs.append(cv_results['test_roc_auc'])\n",
    "        # calculate F1 score again, as scikit learn function had weird results above \n",
    "        # checked and doesn't make a difference\n",
    "        # f1s = 2 * precision * recall / (precision + recall)\n",
    "        # summary dataframe\n",
    "        df = pd.DataFrame(data = {'Model': str(model),\n",
    "                                  'Accuracy': accuracy,\n",
    "                                  'Precision': precision,\n",
    "                                  'Recall': recall,\n",
    "                                  'F1_score': f1,\n",
    "                                  'ROC_AUC': rocauc,\n",
    "                                #   'F1': f1s,\n",
    "                                  'DOF': number_of_model_coeffs,\n",
    "                                  'Coefficients': coefficients}, \n",
    "                                  index = [cv_metrics.index.max()+1])\n",
    "        cv_metrics = pd.concat([cv_metrics, df], axis=0, ignore_index = True)\n",
    "\n",
    "    return cv_metrics, accuracies, precisions, recalls, f1_scores, rocaucs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cross-validation, 5-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/h8/dh7vjkq51437mljbg_vk571c0000gn/T/ipykernel_11913/1759778642.py:46: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1s = 2 * precision * recall / (precision + recall)\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create the models to be tested\n",
    "# mlr_reg = LinearRegression()\n",
    "# ard_reg=ARDRegression(compute_score=True)\n",
    "# #rf_reg = RandomForestRegressor(random_state=42)\n",
    "# #xgb_reg = XGBRegressor(random_state=42)\n",
    "# Put the models in a list to be used for Cross-Validation\n",
    "models = classifiers\n",
    "\n",
    "# def ridge_model(alpha):\n",
    "#     ridgereg = Ridge(alpha=alpha, max_iter=int(1e6))\n",
    "#     return ridgereg\n",
    "\n",
    "# def lasso_model(alpha):\n",
    "#     #Fit the model\n",
    "#     lassoreg = Lasso(alpha=alpha, max_iter=int(1e6))\n",
    "#     return lassoreg\n",
    "\n",
    "#Define the alpha values to test\n",
    "# alpha_lasso = [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04, 0.05,0.075, 0.1,0.15, 0.2, 0.25, 0.5, 0.75, 1] \n",
    "# alpha_ridge = [1, 3, 4, 5, 6, 7, 10, 15, 20, 30, 50]\n",
    "\n",
    "# for a in alpha_lasso:\n",
    "#     models.append(lasso_model(a))\n",
    "# for a in alpha_ridge:    \n",
    "#     models.append(ridge_model(a))\n",
    "\n",
    "# Run the Cross-Validation comparison with the models used in this analysis\n",
    "# cv = n - leave one out cross validation\n",
    "comp, accuracies, precisions, recalls, f1_scores, rocaucs = cv_comparison(models, StandardScaler().fit_transform(X_train), y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation: After cross-validation, MLP Classifier and ADABoost are the best models overall (based on F1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>DOF</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.8063</td>\n",
       "      <td>0.7074</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.753619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC(C=0.025, kernel='linear', random_state=42)</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.7359</td>\n",
       "      <td>0.7934</td>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC(C=1, gamma=2, random_state=42)</td>\n",
       "      <td>0.6708</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.7053</td>\n",
       "      <td>0.6117</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.655174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=5, random_sta...</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.7346</td>\n",
       "      <td>0.7408</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.744076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier(max_depth=5, max_featur...</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.5751</td>\n",
       "      <td>0.8886</td>\n",
       "      <td>0.581510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLPClassifier(alpha=1, max_iter=1000, random_s...</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.8396</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.825414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME', random_s...</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.8307</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.820373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0.5733</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.702117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>QuadraticDiscriminantAnalysis()</td>\n",
       "      <td>0.8106</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.6896</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>0.8058</td>\n",
       "      <td>0.707285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Accuracy  Precision  \\\n",
       "0                KNeighborsClassifier(n_neighbors=3)    0.8448     0.8063   \n",
       "1     SVC(C=0.025, kernel='linear', random_state=42)    0.8758     0.8696   \n",
       "2                 SVC(C=1, gamma=2, random_state=42)    0.6708     0.0000   \n",
       "3  GaussianProcessClassifier(kernel=1**2 * RBF(le...    0.8444     0.7053   \n",
       "4  DecisionTreeClassifier(max_depth=5, random_sta...    0.8320     0.7538   \n",
       "5  RandomForestClassifier(max_depth=5, max_featur...    0.7952     0.8464   \n",
       "6  MLPClassifier(alpha=1, max_iter=1000, random_s...    0.8819     0.8396   \n",
       "7  AdaBoostClassifier(algorithm='SAMME', random_s...    0.8789     0.8103   \n",
       "8                                       GaussianNB()    0.6989     0.5733   \n",
       "9                    QuadraticDiscriminantAnalysis()    0.8106     0.7259   \n",
       "\n",
       "   Recall  F1_score  ROC_AUC        F1  DOF  Coefficients  \n",
       "0  0.7074    0.7494   0.8826  0.753619  NaN           NaN  \n",
       "1  0.7359    0.7934   0.9511  0.797183  NaN           NaN  \n",
       "2  0.0000    0.0000   0.6192       NaN  NaN           NaN  \n",
       "3  0.6117    0.6544   0.9412  0.655174  NaN           NaN  \n",
       "4  0.7346    0.7408   0.7937  0.744076  NaN           NaN  \n",
       "5  0.4429    0.5751   0.8886  0.581510  NaN           NaN  \n",
       "6  0.8117    0.8203   0.9476  0.825414  NaN           NaN  \n",
       "7  0.8307    0.8190   0.9491  0.820373  NaN           NaN  \n",
       "8  0.9056    0.6806   0.9031  0.702117  NaN           NaN  \n",
       "9  0.6896    0.7042   0.8058  0.707285  NaN           NaN  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.7       , 0.7804878 , 0.74285714, 0.71428571, 0.80952381]),\n",
       " array([0.75675676, 0.82051282, 0.78947368, 0.73684211, 0.86363636]),\n",
       " array([0., 0., 0., 0., 0.]),\n",
       " array([0.8       , 0.87179487, 0.85      , 0.75      , 0.        ]),\n",
       " array([0.85      , 0.80851064, 0.57894737, 0.8       , 0.66666667]),\n",
       " array([0.28571429, 0.66666667, 0.64516129, 0.5       , 0.77777778]),\n",
       " array([0.7804878 , 0.87179487, 0.85      , 0.79069767, 0.80851064]),\n",
       " array([0.82926829, 0.79069767, 0.9047619 , 0.74418605, 0.82608696]),\n",
       " array([0.6779661 , 0.63492063, 0.82051282, 0.55555556, 0.71428571]),\n",
       " array([0.7       , 0.66666667, 0.7       , 0.63636364, 0.81818182])]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What kind of scoring does scikit-learn provide?\n",
    "from sklearn.metrics import SCORERS\n",
    "sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def neighborsclass(n,l):\n",
    "    return KNeighborsClassifier(n_neighbors=n,leaf_size=l, n_jobs=4)\n",
    "\n",
    "def decisiontree(criterion, depth, ccp_alpha):\n",
    "    return DecisionTreeClassifier(criterion=criterion, max_depth=depth, ccp_alpha=ccp_alpha,random_state=42)\n",
    "\n",
    "def randomforest(max_depth, n_estimators, max_features):\n",
    "    return RandomForestClassifier(max_depth=max_depth, \n",
    "                                  n_estimators=n_estimators, \n",
    "                                  max_features=max_features, \n",
    "                                  n_jobs=4, \n",
    "                                  random_state=42)\n",
    "\n",
    "def adaboost(n_estimators):\n",
    "    return AdaBoostClassifier(n_estimators=n_estimators, algorithm=\"SAMME\", random_state=42)\n",
    "\n",
    "def mlpc(hidden_layer_sizes, alpha):\n",
    "    return MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, alpha=alpha, max_iter=1000, random_state=42)\n",
    "\n",
    "# Define a function that compares the CV performance of a set of predetermined models \n",
    "def cv_comparison2(models, X, y, cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    cv_metrics = pd.DataFrame(columns = ['Model','Accuracy', 'Precision', 'Recall', 'F1_score', 'ROC_AUC'])\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    rocaucs = []\n",
    "    \n",
    "    # Loop through the models, run a CV, add the average scores to the DataFrame and the scores of \n",
    "    # all CVs to the list\n",
    "    for model in models:\n",
    "        # get cross-validation metrics\n",
    "        cv_results = cross_validate(model, X, y, \n",
    "                                    scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], \n",
    "                                    cv=cv,n_jobs=4)\n",
    "        \n",
    "        # save metrics\n",
    "        accuracy = np.round(cv_results['test_accuracy'].mean(),4)\n",
    "        accuracies.append(cv_results['test_accuracy'])\n",
    "        precision = np.round(cv_results['test_precision'].mean(),4)\n",
    "        precisions.append(cv_results['test_precision'])\n",
    "        recall = np.round(cv_results['test_recall'].mean(),4)\n",
    "        recalls.append(cv_results['test_recall'])\n",
    "        f1 = np.round(cv_results['test_f1'].mean(),4)\n",
    "        f1_scores.append(cv_results['test_f1'])\n",
    "        rocauc = np.round(cv_results['test_roc_auc'].mean(),4)\n",
    "        rocaucs.append(cv_results['test_roc_auc'])\n",
    "        # calculate F1 score again, as scikit learn function had weird results above \n",
    "        # checked and doesn't make a difference\n",
    "        # f1s = 2 * precision * recall / (precision + recall)\n",
    "        # summary dataframe\n",
    "        df = pd.DataFrame(data = {'Model': str(model),\n",
    "                                  'Accuracy': accuracy,\n",
    "                                  'Precision': precision,\n",
    "                                  'Recall': recall,\n",
    "                                  'F1_score': f1,\n",
    "                                  'ROC_AUC': rocauc\n",
    "                                  }, \n",
    "                                  index = [cv_metrics.index.max()+1])\n",
    "        cv_metrics = pd.concat([cv_metrics, df], axis=0, ignore_index = True)\n",
    "\n",
    "    return cv_metrics, accuracies, precisions, recalls, f1_scores, rocaucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "# Gaussian Naive Bayes\n",
    "# no priors => no hyperparameters\n",
    "models.append(GaussianNB())\n",
    "# QDA\n",
    "# no priors => no hyperparameters\n",
    "models.append(QuadraticDiscriminantAnalysis())\n",
    "# Gaussian process\n",
    "# different kernels (and optimizers)\n",
    "for kernel in [1.0 * RBF(1.0),\n",
    "               RBF() + ConstantKernel(constant_value=2),\n",
    "               DotProduct() + WhiteKernel(noise_level=0.5),\n",
    "               DotProduct() + WhiteKernel(), # dot product kernel is invariant to a rotation of the coordinates about the origin, but not translations\n",
    "            #    DotProduct(sigma_0=0) + WhiteKernel(), #homogeneous\n",
    "               1.0 * Matern(length_scale=1.0, nu=1.5), # nu is smoothness of Kernel\n",
    "               1.0 * Matern(length_scale=1.0, nu=2),\n",
    "               1.0 * Matern(length_scale=1.0, nu=2.5),\n",
    "               RationalQuadratic(length_scale=1.0, alpha=1.5),\n",
    "               RationalQuadratic(length_scale=1.0, alpha=5),\n",
    "               ExpSineSquared(length_scale=1, periodicity=1,) # periodic kernel\n",
    "               ]:\n",
    "    models.append(GaussianProcessClassifier(kernel=kernel, random_state=42, n_jobs=4))\n",
    "# KNearest neighbor\n",
    "for n in [2,3,4,5,7,10]:\n",
    "    # leaf size doesn't have a lot of effect on this dataset\n",
    "    # could remove this inner loop to decrease number of models\n",
    "    # for l in [10, 30, 100]:\n",
    "        # models.append(neighborsclass(n,l))\n",
    "    models.append(neighborsclass(n,30))\n",
    "# decision tree\n",
    "for criterion in ['gini', 'entropy']:\n",
    "    for depth in [2, 5, 10, None]:\n",
    "        for ccp_alpha in [0, 2, 5, 10]:\n",
    "            models.append(decisiontree(criterion, depth, ccp_alpha))\n",
    "# random forest\n",
    "for max_depth in [3,5,10]: #maximum depth of the tree\n",
    "    for n_estimators in [10, 20, 40, 80]: # number of trees in forest\n",
    "         for max_features in [\"sqrt\", \"log2\"]: # number of features to consider when looking for the best split\n",
    "            models.append(randomforest(max_depth, n_estimators, max_features))\n",
    "# AdaBoost\n",
    "for n_estimators in [5, 10, 20, 50, 100]:\n",
    "    models.append(adaboost(n_estimators))\n",
    "# Multilayer Perceptron\n",
    "for hidden_layer_sizes in [(50,),(100,), (200,)]:\n",
    "    for alpha in [1e-5, 1e-3, 1, 10]: #L2 regularization strength\n",
    "        models.append(mlpc(hidden_layer_sizes, alpha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "comp, accuracies, precisions, recalls, f1_scores, rocaucs = cv_comparison2(models, StandardScaler().fit_transform(X_train), y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GaussianProcessClassifier(kernel=RationalQuadr...</td>\n",
       "      <td>0.6708</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianProcessClassifier(kernel=RationalQuadr...</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianProcessClassifier(kernel=RBF(length_sc...</td>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.7793</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * Matern...</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.8574</td>\n",
       "      <td>0.7926</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>0.9527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * Matern...</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>0.7831</td>\n",
       "      <td>0.8144</td>\n",
       "      <td>0.9520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * Matern...</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.7831</td>\n",
       "      <td>0.8109</td>\n",
       "      <td>0.9514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianProcessClassifier(kernel=DotProduct(si...</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.8408</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0.9507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier(kernel=DotProduct(si...</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.8408</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0.9507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.7053</td>\n",
       "      <td>0.6117</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>0.9412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KNeighborsClassifier(n_jobs=4, n_neighbors=10)</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.6506</td>\n",
       "      <td>0.7616</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNeighborsClassifier(n_jobs=4, n_neighbors=7)</td>\n",
       "      <td>0.8633</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.9236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsClassifier(n_jobs=4)</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.7074</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.9116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0.5733</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>0.9031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNeighborsClassifier(n_jobs=4, n_neighbors=4)</td>\n",
       "      <td>0.8509</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier(n_jobs=4, n_neighbors=3)</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.8063</td>\n",
       "      <td>0.7074</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.8826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsClassifier(n_jobs=4, n_neighbors=2)</td>\n",
       "      <td>0.8107</td>\n",
       "      <td>0.8886</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.6277</td>\n",
       "      <td>0.8498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QuadraticDiscriminantAnalysis()</td>\n",
       "      <td>0.8106</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.6896</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>0.8058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GaussianProcessClassifier(kernel=ExpSineSquare...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  Accuracy  Precision  \\\n",
       "9   GaussianProcessClassifier(kernel=RationalQuadr...    0.6708     0.0000   \n",
       "10  GaussianProcessClassifier(kernel=RationalQuadr...    0.8758     0.9052   \n",
       "3   GaussianProcessClassifier(kernel=RBF(length_sc...    0.8726     0.9023   \n",
       "6   GaussianProcessClassifier(kernel=1**2 * Matern...    0.8850     0.8574   \n",
       "7   GaussianProcessClassifier(kernel=1**2 * Matern...    0.8819     0.8553   \n",
       "8   GaussianProcessClassifier(kernel=1**2 * Matern...    0.8788     0.8493   \n",
       "4   GaussianProcessClassifier(kernel=DotProduct(si...    0.8818     0.8408   \n",
       "5   GaussianProcessClassifier(kernel=DotProduct(si...    0.8818     0.8408   \n",
       "2   GaussianProcessClassifier(kernel=1**2 * RBF(le...    0.8444     0.7053   \n",
       "17     KNeighborsClassifier(n_jobs=4, n_neighbors=10)    0.8663     0.9213   \n",
       "16      KNeighborsClassifier(n_jobs=4, n_neighbors=7)    0.8633     0.8811   \n",
       "15                     KNeighborsClassifier(n_jobs=4)    0.8602     0.8464   \n",
       "0                                        GaussianNB()    0.6989     0.5733   \n",
       "14      KNeighborsClassifier(n_jobs=4, n_neighbors=4)    0.8509     0.9293   \n",
       "13      KNeighborsClassifier(n_jobs=4, n_neighbors=3)    0.8448     0.8063   \n",
       "12      KNeighborsClassifier(n_jobs=4, n_neighbors=2)    0.8107     0.8886   \n",
       "1                     QuadraticDiscriminantAnalysis()    0.8106     0.7259   \n",
       "11  GaussianProcessClassifier(kernel=ExpSineSquare...       NaN        NaN   \n",
       "\n",
       "    Recall  F1_score  ROC_AUC  \n",
       "9   0.0000    0.0000   0.9605  \n",
       "10  0.6978    0.7864   0.9567  \n",
       "3   0.6883    0.7793   0.9567  \n",
       "6   0.7926    0.8205   0.9527  \n",
       "7   0.7831    0.8144   0.9520  \n",
       "8   0.7831    0.8109   0.9514  \n",
       "4   0.8013    0.8180   0.9507  \n",
       "5   0.8013    0.8180   0.9507  \n",
       "2   0.6117    0.6544   0.9412  \n",
       "17  0.6506    0.7616   0.9400  \n",
       "16  0.6792    0.7656   0.9236  \n",
       "15  0.7074    0.7680   0.9116  \n",
       "0   0.9056    0.6806   0.9031  \n",
       "14  0.5935    0.7223   0.9000  \n",
       "13  0.7074    0.7494   0.8826  \n",
       "12  0.4900    0.6277   0.8498  \n",
       "1   0.6896    0.7042   0.8058  \n",
       "11     NaN       NaN      NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.sort_values(by=['ROC_AUC', 'F1_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
