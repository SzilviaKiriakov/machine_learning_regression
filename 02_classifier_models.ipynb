{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "# from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "# from sklearn.metrics import PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_excel('./data/PCOS_data_without_infertility.xlsx', sheet_name=\"Full_new\")\n",
    "dataset2.drop(columns = 'Unnamed: 44', inplace = True)\n",
    "dataset2.loc[dataset2['II    beta-HCG(mIU/mL)'] == '1.99.', 'II    beta-HCG(mIU/mL)'] = 1.99\n",
    "dataset2['II    beta-HCG(mIU/mL)'] = dataset2['II    beta-HCG(mIU/mL)'].astype(float)\n",
    "dataset2.loc[dataset2['AMH(ng/mL)'] == 'a', 'AMH(ng/mL)'] = np.nan\n",
    "dataset2['AMH(ng/mL)'] = dataset2['AMH(ng/mL)'].astype(float)\n",
    "dataset2 = dataset2.dropna()\n",
    "\n",
    "y = dataset2['PCOS (Y/N)']\n",
    "features = list(dataset2.columns)\n",
    "features.remove('Sl. No')\n",
    "features.remove('Patient File No.')\n",
    "features.remove('PCOS (Y/N)')\n",
    "X = dataset2[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without hyperparameter optimization, linear SVM, Gaussian process and Neural Net have the highest accuracy and F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn's f1-score calculates something else\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors 0.7480916030534351 0.8903654485049834 0.8903654485049833\n",
      "Linear SVM 0.8175182481751825 0.9152542372881356 0.9152542372881356\n",
      "RBF SVM 0.0 0.8066298342541436 0.8066298342541437\n",
      "Gaussian Process 0.8029197080291971 0.9084745762711866 0.9084745762711864\n",
      "Decision Tree 0.7083333333333334 0.8541666666666666 0.8541666666666666\n",
      "Random Forest 0.5544554455445545 0.86404833836858 0.8640483383685801\n",
      "Neural Net 0.8027210884353742 0.8982456140350877 0.8982456140350877\n",
      "AdaBoost 0.7794117647058824 0.8986486486486487 0.8986486486486487\n",
      "Naive Bayes 0.6598984771573604 0.7148936170212765 0.7148936170212766\n",
      "QDA 0.7307692307692307 0.8478260869565217 0.8478260869565217\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf = make_pipeline(StandardScaler(), clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # accuracy\n",
    "    score = clf.score(X_test, y_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # f1 score\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # true positive\n",
    "    tp = cm[0,0]\n",
    "    tn = cm[1,1]\n",
    "    # false positive\n",
    "    fp = cm[0,1]\n",
    "    # false negative\n",
    "    fn = cm[1,0]\n",
    "    # Precision is the fraction of the correctly classified instances from the total classified instances\n",
    "    precision = tp / (tp + fp)\n",
    "    # Recall is the fraction of the correctly classified instances from the total classified instances\n",
    "    recall = tp / (tp + fn)\n",
    "    # F1-score\n",
    "    f1s = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    print(name, f1, f1s, 2*tp / (2*tp+fp+fn))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "df = pd.DataFrame(data = {'F1score': f1s}, index = [0])\n",
    "df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# Define a function that compares the CV perfromance of a set of predetrmined models \n",
    "def cv_comparison(models, X, y, cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    cv_metrics = pd.DataFrame(columns = ['Model','Accuracy', 'Precision', 'Recall', 'F1_score', 'ROC_AUC', 'F1', 'DOF', 'Coefficients'])\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    rocaucs = []\n",
    "    \n",
    "    # Loop through the models, run a CV, add the average scores to the DataFrame and the scores of \n",
    "    # all CVs to the list\n",
    "    for model in models:\n",
    "        # calculate model complexity\n",
    "        number_of_model_coeffs = 0\n",
    "        try:\n",
    "            for i in model.coef_:\n",
    "                if i != 0:\n",
    "                    number_of_model_coeffs +=1\n",
    "            coefficients = model.coef_\n",
    "        except:\n",
    "            number_of_model_coeffs = np.nan\n",
    "            coefficients = np.nan\n",
    "        \n",
    "        # get cross-validation metrics\n",
    "        cv_results = cross_validate(model, X, y, \n",
    "                                    scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], \n",
    "                                    cv=cv,n_jobs=4)\n",
    "        \n",
    "        # save metrics\n",
    "        accuracy = np.round(cv_results['test_accuracy'].mean(),4)\n",
    "        accuracies.append(cv_results['test_accuracy'])\n",
    "        precision = np.round(cv_results['test_precision'].mean(),4)\n",
    "        precisions.append(cv_results['test_precision'])\n",
    "        recall = np.round(cv_results['test_recall'].mean(),4)\n",
    "        recalls.append(cv_results['test_recall'])\n",
    "        f1 = np.round(cv_results['test_f1'].mean(),4)\n",
    "        f1_scores.append(cv_results['test_f1'])\n",
    "        rocauc = np.round(cv_results['test_roc_auc'].mean(),4)\n",
    "        rocaucs.append(cv_results['test_roc_auc'])\n",
    "        # calculate F1 score again, as scikit learn function had weird results above \n",
    "        # checked and doesn't make a difference\n",
    "        # f1s = 2 * precision * recall / (precision + recall)\n",
    "        # summary dataframe\n",
    "        df = pd.DataFrame(data = {'Model': str(model),\n",
    "                                  'Accuracy': accuracy,\n",
    "                                  'Precision': precision,\n",
    "                                  'Recall': recall,\n",
    "                                  'F1_score': f1,\n",
    "                                  'ROC_AUC': rocauc,\n",
    "                                #   'F1': f1s,\n",
    "                                  'DOF': number_of_model_coeffs,\n",
    "                                  'Coefficients': coefficients}, \n",
    "                                  index = [cv_metrics.index.max()+1])\n",
    "        cv_metrics = pd.concat([cv_metrics, df], axis=0, ignore_index = True)\n",
    "\n",
    "    return cv_metrics, accuracies, precisions, recalls, f1_scores, rocaucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/h8/dh7vjkq51437mljbg_vk571c0000gn/T/ipykernel_11913/1759778642.py:46: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1s = 2 * precision * recall / (precision + recall)\n",
      "/Users/szilvia/.pyenv/versions/python-3.8.5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create the models to be tested\n",
    "# mlr_reg = LinearRegression()\n",
    "# ard_reg=ARDRegression(compute_score=True)\n",
    "# #rf_reg = RandomForestRegressor(random_state=42)\n",
    "# #xgb_reg = XGBRegressor(random_state=42)\n",
    "# Put the models in a list to be used for Cross-Validation\n",
    "models = classifiers\n",
    "\n",
    "# def ridge_model(alpha):\n",
    "#     ridgereg = Ridge(alpha=alpha, max_iter=int(1e6))\n",
    "#     return ridgereg\n",
    "\n",
    "# def lasso_model(alpha):\n",
    "#     #Fit the model\n",
    "#     lassoreg = Lasso(alpha=alpha, max_iter=int(1e6))\n",
    "#     return lassoreg\n",
    "\n",
    "#Define the alpha values to test\n",
    "# alpha_lasso = [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04, 0.05,0.075, 0.1,0.15, 0.2, 0.25, 0.5, 0.75, 1] \n",
    "# alpha_ridge = [1, 3, 4, 5, 6, 7, 10, 15, 20, 30, 50]\n",
    "\n",
    "# for a in alpha_lasso:\n",
    "#     models.append(lasso_model(a))\n",
    "# for a in alpha_ridge:    \n",
    "#     models.append(ridge_model(a))\n",
    "\n",
    "# Run the Cross-Validation comparison with the models used in this analysis\n",
    "# cv = n - leave one out cross validation\n",
    "comp, accuracies, precisions, recalls, f1_scores, rocaucs = cv_comparison(models, StandardScaler().fit_transform(X_train), y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>DOF</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.8063</td>\n",
       "      <td>0.7074</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.753619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC(C=0.025, kernel='linear', random_state=42)</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.7359</td>\n",
       "      <td>0.7934</td>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC(C=1, gamma=2, random_state=42)</td>\n",
       "      <td>0.6708</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.7053</td>\n",
       "      <td>0.6117</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.655174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=5, random_sta...</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.7346</td>\n",
       "      <td>0.7408</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.744076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier(max_depth=5, max_featur...</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.5751</td>\n",
       "      <td>0.8886</td>\n",
       "      <td>0.581510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLPClassifier(alpha=1, max_iter=1000, random_s...</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.8396</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.825414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME', random_s...</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.8307</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.820373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0.5733</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.702117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>QuadraticDiscriminantAnalysis()</td>\n",
       "      <td>0.8106</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.6896</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>0.8058</td>\n",
       "      <td>0.707285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Accuracy  Precision  \\\n",
       "0                KNeighborsClassifier(n_neighbors=3)    0.8448     0.8063   \n",
       "1     SVC(C=0.025, kernel='linear', random_state=42)    0.8758     0.8696   \n",
       "2                 SVC(C=1, gamma=2, random_state=42)    0.6708     0.0000   \n",
       "3  GaussianProcessClassifier(kernel=1**2 * RBF(le...    0.8444     0.7053   \n",
       "4  DecisionTreeClassifier(max_depth=5, random_sta...    0.8320     0.7538   \n",
       "5  RandomForestClassifier(max_depth=5, max_featur...    0.7952     0.8464   \n",
       "6  MLPClassifier(alpha=1, max_iter=1000, random_s...    0.8819     0.8396   \n",
       "7  AdaBoostClassifier(algorithm='SAMME', random_s...    0.8789     0.8103   \n",
       "8                                       GaussianNB()    0.6989     0.5733   \n",
       "9                    QuadraticDiscriminantAnalysis()    0.8106     0.7259   \n",
       "\n",
       "   Recall  F1_score  ROC_AUC        F1  DOF  Coefficients  \n",
       "0  0.7074    0.7494   0.8826  0.753619  NaN           NaN  \n",
       "1  0.7359    0.7934   0.9511  0.797183  NaN           NaN  \n",
       "2  0.0000    0.0000   0.6192       NaN  NaN           NaN  \n",
       "3  0.6117    0.6544   0.9412  0.655174  NaN           NaN  \n",
       "4  0.7346    0.7408   0.7937  0.744076  NaN           NaN  \n",
       "5  0.4429    0.5751   0.8886  0.581510  NaN           NaN  \n",
       "6  0.8117    0.8203   0.9476  0.825414  NaN           NaN  \n",
       "7  0.8307    0.8190   0.9491  0.820373  NaN           NaN  \n",
       "8  0.9056    0.6806   0.9031  0.702117  NaN           NaN  \n",
       "9  0.6896    0.7042   0.8058  0.707285  NaN           NaN  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00076699, 0.00075388, 0.00118923, 0.00083423, 0.00111485]),\n",
       " 'score_time': array([0.00794291, 0.02807808, 0.04851103, 0.04176569, 0.03201222]),\n",
       " 'test_accuracy': array([0.66153846, 0.67692308, 0.640625  , 0.6875    , 0.671875  ]),\n",
       " 'test_precision': array([0.44444444, 0.52      , 0.45      , 0.53846154, 0.5       ]),\n",
       " 'test_recall': array([0.19047619, 0.59090909, 0.42857143, 0.33333333, 0.38095238]),\n",
       " 'test_f1': array([0.26666667, 0.55319149, 0.43902439, 0.41176471, 0.43243243]),\n",
       " 'test_roc_auc': array([0.55735931, 0.62737844, 0.60354374, 0.62236988, 0.64839424])}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30103265, -1.2985318 , -2.42099129, ...,  0.55344535,\n",
       "         1.36018065,  0.22998522],\n",
       "       [-0.82827818,  0.51661109,  0.59858974, ..., -1.4909103 ,\n",
       "        -0.18547918, -0.86199486],\n",
       "       [-0.64005971, -0.10961321, -0.57569177, ...,  0.55344535,\n",
       "         0.74191672, -1.76406536],\n",
       "       ...,\n",
       "       [-1.01649665, -0.32743036,  0.93409874, ...,  0.84549616,\n",
       "         0.74191672,  0.08755303],\n",
       "       [ 0.11281418,  1.06115395,  0.09532624, ...,  0.84549616,\n",
       "         1.05104869, -0.24478873],\n",
       "       [ 1.24212501,  0.45308108, -1.24670978, ...,  0.55344535,\n",
       "        -2.04027098,  1.3219653 ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
